{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scenario': 'orchestrator', 'training_folder': '../..', 'params': {'general': {'periods': ['test']}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "params = {'general':{'periods':['test']}}\n",
    "default = {'scenario':'orchestrator','training_folder': '../..', 'params': params} # Default execution parameters\n",
    "# here sceneario: demand is only use not on lambda.\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00e9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numba import jit, njit\n",
    "import numba as nb\n",
    "from quetzal.model import stepmodel\n",
    "from shapely.geometry import LineString\n",
    "from quetzal.io.gtfs_reader.importer import get_epsg\n",
    "from quetzal.io import excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505c32e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Lambda :  False\n",
      "input folder:  ['../../inputs/test/']\n",
      "output folder:  ../../scenarios/orchestrator/outputs/\n",
      "scen folder :  ['../../scenarios/test/outputs/']\n"
     ]
    }
   ],
   "source": [
    "periods = argv['params']['general']['periods']\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "print('On Lambda : ', on_lambda)\n",
    "training_folder = argv['training_folder']\n",
    "input_folder = training_folder +r'/inputs/'\n",
    "if on_lambda:\n",
    "    bucket_name = 'quetzal-immense' #os.environ.get('BUCKET_NAME')\n",
    "    output_folder = training_folder + '/outputs/'\n",
    "    scenario_folders = []\n",
    "    input_folders = []\n",
    "    for p in periods:\n",
    "        folder = 's3://' + bucket_name + '/' + p + '/outputs/'\n",
    "        scenario_folders.append(folder)\n",
    "        input_folders.append(input_folder + p + '/')\n",
    "\n",
    "else:\n",
    "    output_folder = training_folder + '/scenarios/' + argv['scenario'] + '/outputs/'\n",
    "    scenario_folders = []\n",
    "    input_folders = []\n",
    "    for p in periods:\n",
    "        folder = training_folder + '/scenarios/' + p + '/outputs/'\n",
    "        scenario_folders.append(folder)\n",
    "        input_folders.append(input_folder + p + '/')\n",
    "    \n",
    "print('input folder: ', input_folders)\n",
    "print('output folder: ', output_folder)\n",
    "print('scen folder : ', scenario_folders)\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dcb24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#var, ancestry = excel.read_var(file=input_folder+'/parameters.xlsx', scenario=period, return_ancestry=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd746b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95a65cd0",
   "metadata": {},
   "source": [
    "# modal shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb7f48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 12.3.2 Incremental or Pivot-point Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d25157cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt_part(pt_los:pd.DataFrame, \n",
    "                car_los:pd.DataFrame, \n",
    "                method:str='kirchhoff',\n",
    "                power:float=-1.42,\n",
    "                part_max:float=1) -> pd.DataFrame:\n",
    "    \n",
    "    cols = ['origin','destination','time']\n",
    "    los = pt_los[cols].merge(car_los[cols],on=['origin','destination'],how='inner')\n",
    "    los = los.rename(columns = {'time_x':'time_pt','time_y':'time_car'})\n",
    "    los['time_ratio'] = los['time_pt'] / los['time_car']\n",
    "    if method == 'kirchhoff':\n",
    "        los['pt_part'] = los['time_ratio'].apply(lambda x: min(x**(power), part_max))\n",
    "    else:\n",
    "        print('method not recognized')\n",
    "    return los\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53e150cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../inputs/test/\n"
     ]
    }
   ],
   "source": [
    "for period, ref_folder, scen_folder in zip(periods,input_folders,scenario_folders):\n",
    "    print(ref_folder)\n",
    "    ref_pt_skim = pd.read_csv(ref_folder+'skims/pt_skim.csv')\n",
    "    ref_car_skim = pd.read_csv(ref_folder+'skims/car_skim.csv')\n",
    "    pt_skim = pd.read_csv(scen_folder+'pt_skim.csv')\n",
    "    car_skim = pd.read_csv(scen_folder+'car_skim.csv')\n",
    "    volumes = pd.read_csv(ref_folder+'volumes/volumes.csv')\n",
    "    volumes = volumes.set_index('index')\n",
    "\n",
    "    ref_pt_part = get_pt_part(ref_pt_skim, ref_car_skim)\n",
    "    pt_part = get_pt_part(pt_skim, car_skim)\n",
    "    \n",
    "    ref_pt_part = ref_pt_part.set_index(['origin','destination'])['pt_part'].to_dict()\n",
    "    pt_part['ref_pt_part'] = pt_part.set_index(['origin','destination']).index.map(ref_pt_part.get)\n",
    "    pt_part['transfert_prob'] = pt_part['pt_part'] - pt_part['ref_pt_part']\n",
    "    \n",
    "    transfert_prob = pt_part.set_index(['origin','destination'])['transfert_prob'].to_dict()\n",
    "    volumes['transfert_prob'] = volumes.set_index(['origin','destination']).index.map(transfert_prob.get)\n",
    "    volumes['transfert'] = volumes['pt'] * volumes['transfert_prob']\n",
    "    volumes['pt'] = volumes['pt'] + volumes['transfert']\n",
    "    volumes['car'] = volumes['pt'] - volumes['transfert']\n",
    "    \n",
    "    volumes[['origin','destination','pt','car']].to_csv(output_folder+'volume_'+period+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f2563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668e272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877fac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523505d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4878015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
