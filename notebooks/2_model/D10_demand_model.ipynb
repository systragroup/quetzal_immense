{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scenario': 'orchestrator', 'training_folder': '../..', 'params': {'general': {'periods': ['am', 'pm', 'ip', 'op']}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "#if argv['params']['general'].get('scenario_path_S3') contains immense s3 path (ex: uuid-123-456-789/)\n",
    "params = {'general':{'periods':['am','pm','ip','op']}}\n",
    "default = {'scenario':'orchestrator','training_folder': '../..', 'params': params} # Default execution parameters\n",
    "# here sceneario: demand is only use not on lambda.\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00e9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numba import jit, njit\n",
    "import numba as nb\n",
    "from quetzal.model import stepmodel\n",
    "from shapely.geometry import LineString\n",
    "from quetzal.io.gtfs_reader.importer import get_epsg\n",
    "from quetzal.io import excel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "505c32e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Lambda :  False\n",
      "input folder:  ['../../inputs/am/', '../../inputs/pm/', '../../inputs/ip/', '../../inputs/op/']\n",
      "output folder:  ../../scenarios/orchestrator/outputs/\n",
      "scen folder :  ['../../scenarios/am/outputs/', '../../scenarios/pm/outputs/', '../../scenarios/ip/outputs/', '../../scenarios/op/outputs/']\n"
     ]
    }
   ],
   "source": [
    "periods = argv['params']['general']['periods']\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "print('On Lambda : ', on_lambda)\n",
    "training_folder = argv['training_folder']\n",
    "input_folder = training_folder +r'/inputs/'\n",
    "if on_lambda:\n",
    "    bucket_name = 'quetzal-immense' #os.environ.get('BUCKET_NAME')\n",
    "    output_folder = training_folder + '/outputs/'\n",
    "    scenario_folder = training_folder + '/inputs/'\n",
    "    scenario_folders = []\n",
    "    input_folders = []\n",
    "    for p in periods:\n",
    "        folder = 's3://' + bucket_name + '/' + p + '/outputs/'\n",
    "        scenario_folders.append(folder)\n",
    "        input_folders.append(input_folder + p + '/')\n",
    "\n",
    "else:\n",
    "    output_folder = training_folder + '/scenarios/' + argv['scenario'] + '/outputs/'\n",
    "    scenario_folder = training_folder + '/scenarios/' + argv['scenario'] + '/inputs/'\n",
    "    scenario_folders = []\n",
    "    input_folders = []\n",
    "    for p in periods:\n",
    "        folder = training_folder + '/scenarios/' + p + '/outputs/'\n",
    "        scenario_folders.append(folder)\n",
    "        input_folders.append(input_folder + p + '/')\n",
    "    \n",
    "print('input folder: ', input_folders)\n",
    "print('output folder: ', output_folder)\n",
    "print('scen folder : ', scenario_folders)\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb24f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f356591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd746b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa4bad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_volumes = pd.read_csv(input_folder+'base/volumes/volumes.csv')\n",
    "base_volumes.index.name = 'index'\n",
    "volumes = base_volumes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9de202b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes['origin'] = 'zone_' + volumes['origin'].astype(str)\n",
    "volumes['destination'] = 'zone_' + volumes['destination'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f4178c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_set = set(zip(volumes['origin'],volumes['destination'],volumes['time_period'],volumes['vehicle_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6047b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'C_other':'car',\n",
    "            'C_EB':'car',\n",
    "            'BPAX':'pt', \n",
    "            'RPAX':'pt'}\n",
    "volumes['mode'] = volumes['vehicle_class'].apply(class_dict.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07a86a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = volumes.groupby(['origin','destination','time_period','mode'])[['volume']].agg(sum).unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dab74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes.columns = ['origin','destination','time_period','car','pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3447464",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = volumes.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bad57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d849b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_dict={'am':'AM','pm':'PM','ip':'IP','op':'OP'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49029ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n",
      "pm\n",
      "ip\n",
      "op\n"
     ]
    }
   ],
   "source": [
    "#pour martin\n",
    "cols = ['origin', 'destination', 'time_period', 'vehicle_class', 'time']\n",
    "skim = pd.DataFrame()\n",
    "ref_skim = pd.DataFrame()\n",
    "for period, ref_folder, scen_folder in zip(periods,input_folders,scenario_folders):\n",
    "    print(period)\n",
    "    ref_pt_skim = pd.read_csv(scen_folder+'ref_pt_skim.csv')\n",
    "    pt_skim = pd.read_csv(scen_folder+'pt_skim.csv')\n",
    "    \n",
    "    ref_pt_skim['time_period'] = period_dict[period]\n",
    "    pt_skim['time_period'] = period_dict[period]\n",
    "\n",
    "    ref_skim = pd.concat([ref_skim, ref_pt_skim[cols]])\n",
    "    skim = pd.concat([skim, pt_skim[cols]])\n",
    "    \n",
    "    # skims pour martin:\n",
    "    # origin, destination, time_period, vehicle_class, time,\n",
    "    # ca: pt et road dans le meme fichier (vehicle_class => pt ou road)\n",
    "    # ref et pas ref."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f24b924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_car_skim = pd.read_csv(input_folder+ 'base/road_skims.csv')\n",
    "car_skim = pd.read_csv(scenario_folder+'road_skims.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f87059db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_car_skim['origin'] = 'zone_' + ref_car_skim['origin'].astype(str)\n",
    "ref_car_skim['destination'] = 'zone_' + ref_car_skim['destination'].astype(str)\n",
    "\n",
    "car_skim['origin'] = 'zone_' + car_skim['origin'].astype(str)\n",
    "car_skim['destination'] = 'zone_' + car_skim['destination'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16703bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fdb4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # export skims for martin\n",
    "    cols = ['origin', 'destination', 'time_period', 'vehicle_class', 'time','distance']\n",
    "    ref_skim = pd.concat([ref_skim, ref_car_skim[cols]])\n",
    "    skim = pd.concat([skim, car_skim[cols]])\n",
    "\n",
    "    skim = skim.set_index(['origin','destination','time_period','vehicle_class']).loc[od_set].reset_index()\n",
    "    ref_skim = ref_skim.set_index(['origin','destination','time_period','vehicle_class']).loc[od_set].reset_index()\n",
    "\n",
    "    skim.reset_index(drop=True).to_csv(output_folder+'skims'+'.csv')\n",
    "    ref_skim.reset_index(drop=True).to_csv(output_folder+'ref_skims'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27970da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549bb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0243de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95a65cd0",
   "metadata": {},
   "source": [
    "# modal shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f1807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d25157cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt_part(pt_los:pd.DataFrame, \n",
    "                car_los:pd.DataFrame, \n",
    "                method:str='kirchhoff',\n",
    "                power:float=-1.42,\n",
    "                part_max:float=1) -> pd.DataFrame:\n",
    "    \n",
    "    cols = ['origin','destination','time']\n",
    "    los = pt_los[cols].merge(car_los[cols],on=['origin','destination'],how='inner')\n",
    "    los = los.rename(columns = {'time_x':'time_pt','time_y':'time_car'})\n",
    "    los['time_ratio'] = los['time_pt'] / los['time_car']\n",
    "    if method == 'kirchhoff':\n",
    "        los['pt_part'] = los['time_ratio'].apply(lambda x: min(x**(power), part_max))\n",
    "    else:\n",
    "        print('method not recognized')\n",
    "    return los\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53e150cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n",
      "pm\n",
      "ip\n",
      "op\n"
     ]
    }
   ],
   "source": [
    "for period, ref_folder, scen_folder in zip(periods,input_folders,scenario_folders):\n",
    "    print(period)\n",
    "    ref_pt_skim = pd.read_csv(scen_folder+'ref_pt_skim.csv')\n",
    "    pt_skim = pd.read_csv(scen_folder+'pt_skim.csv')\n",
    "    ref_car_los = ref_car_skim[ref_car_skim['time_period']== period_dict[period]]\n",
    "    car_los = car_skim[car_skim['time_period']== period_dict[period]]\n",
    "    \n",
    "    v = volumes[volumes['time_period'] == period_dict[period]]\n",
    "    \n",
    "    ref_pt_part = get_pt_part(ref_pt_skim, ref_car_los)\n",
    "    pt_part = get_pt_part(pt_skim, car_los)\n",
    "    \n",
    "    ref_pt_part = ref_pt_part.set_index(['origin','destination'])['pt_part'].to_dict()\n",
    "    pt_part['ref_pt_part'] = pt_part.set_index(['origin','destination']).index.map(ref_pt_part.get)\n",
    "    pt_part['transfert_prob'] = pt_part['pt_part'] - pt_part['ref_pt_part']\n",
    "    \n",
    "    transfert_prob = pt_part.set_index(['origin','destination'])['transfert_prob'].to_dict()\n",
    "    v['transfert_prob'] = v.set_index(['origin','destination']).index.map(transfert_prob.get)\n",
    "    v['transfert'] = v['pt'] * v['transfert_prob']\n",
    "    \n",
    "    volumes.loc[volumes['time_period'] == period_dict[period],'new_pt'] =v['pt'] + v['transfert']\n",
    "    volumes.loc[volumes['time_period'] == period_dict[period],'new_car'] = v['car'] - v['transfert']\n",
    "    \n",
    "    #volumes[['origin','destination','pt','car']].to_csv(output_folder+'volume_'+period+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "972fa6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes['new_car'] = volumes['new_car'].fillna(volumes['car'])\n",
    "volumes['new_pt'] = volumes['new_pt'].fillna(volumes['pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad5bc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes['car_growth'] = volumes['new_car']/volumes['car']\n",
    "volumes['pt_growth'] = volumes['new_pt']/volumes['pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9deb004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_volumes['o'] = 'zone_' + base_volumes['origin'].astype(str)\n",
    "base_volumes['d'] = 'zone_' + base_volumes['destination'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c704b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_dict = volumes.set_index(['origin','destination','time_period'])['car_growth'].to_dict()\n",
    "pt_dict = volumes.set_index(['origin','destination','time_period'])['pt_growth'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2f2757a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_volumes['pt_growth'] = base_volumes.set_index(['o','d','time_period']).index.map(pt_dict.get)\n",
    "base_volumes['car_growth'] = base_volumes.set_index(['o','d','time_period']).index.map(car_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f44bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f8b5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_filter = base_volumes['vehicle_class'].isin(['C_other', 'C_EB'])\n",
    "base_volumes.loc[car_filter,'volume'] = base_volumes.loc[car_filter,'volume'] * base_volumes.loc[car_filter,'car_growth'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fd34bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_filter = base_volumes['vehicle_class'].isin(['BPAX', 'RPAX'])\n",
    "base_volumes.loc[pt_filter,'volume'] = base_volumes.loc[pt_filter,'volume'] * base_volumes.loc[pt_filter,'pt_growth'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "746a795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_volumes = base_volumes.drop(columns=['o','d','pt_growth','car_growth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4aa0c4",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1532832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_volumes.to_csv(output_folder+'volumes'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020af9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to immense bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "573f76f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if argv['params']['general'].get('scenario_path_S3'):\n",
    "    import boto3\n",
    "    from io import StringIO\n",
    "\n",
    "    s3_path = argv['params']['general'].get('scenario_path_S3')\n",
    "    session = boto3.Session(region_name='eu-west-1')\n",
    "    s3 = session.client('s3')\n",
    "    \n",
    "    csv_buffer = StringIO()\n",
    "    base_volumes.to_csv(csv_buffer)\n",
    "\n",
    "    s3.put_object(Body=csv_buffer.getvalue(),\n",
    "                  Bucket='ir-dev-external-shared-eu-west-1-common', \n",
    "                  Key=s3_path+'outputs/volume.csv',\n",
    "                  ACL='bucket-owner-full-control' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6784a3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8773106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2780d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e041d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e109ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
