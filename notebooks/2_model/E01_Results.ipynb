{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scenario': 'orchestrator2', 'training_folder': '../..', 'params': {'general': {'periods': ['am', 'pm', 'ip', 'op']}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "#if argv['params']['general'].get('scenario_path_S3') contains immense s3 path (ex: uuid-123-456-789/)\n",
    "params = {'general':{'periods':['am','pm','ip','op']}}\n",
    "default = {'scenario':'orchestrator2','training_folder': '../..', 'params': params} # Default execution parameters\n",
    "# here sceneario: demand is only use not on lambda.\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00e9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numba import jit, njit\n",
    "import numba as nb\n",
    "from quetzal.model import stepmodel\n",
    "from shapely.geometry import LineString\n",
    "from quetzal.io.gtfs_reader.importer import get_epsg\n",
    "from quetzal.io import excel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "505c32e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Lambda :  False\n",
      "input folder:  ['../../inputs/am/', '../../inputs/pm/', '../../inputs/ip/', '../../inputs/op/']\n",
      "output folder:  ../../scenarios/orchestrator2/outputs/\n",
      "scen folder :  ['../../scenarios/am/', '../../scenarios/pm/', '../../scenarios/ip/', '../../scenarios/op/']\n"
     ]
    }
   ],
   "source": [
    "periods = argv['params']['general']['periods']\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "print('On Lambda : ', on_lambda)\n",
    "training_folder = argv['training_folder']\n",
    "input_folder = training_folder +r'/inputs/'\n",
    "if on_lambda:\n",
    "    bucket_name = 'quetzal-immense' #os.environ.get('BUCKET_NAME')\n",
    "    output_folder = training_folder + '/outputs/'\n",
    "    scenario_folder = training_folder + '/inputs/'\n",
    "    scenario_folders = []\n",
    "    input_folders = []\n",
    "    for p in periods:\n",
    "        folder = 's3://' + bucket_name + '/' + p + '/'\n",
    "        scenario_folders.append(folder)\n",
    "        input_folders.append(input_folder + p + '/')\n",
    "\n",
    "else:\n",
    "    output_folder = training_folder + '/scenarios/' + argv['scenario'] + '/outputs/'\n",
    "    scenario_folder = training_folder + '/scenarios/' + argv['scenario'] + '/inputs/'\n",
    "    scenario_folders = []\n",
    "    input_folders = []\n",
    "    for p in periods:\n",
    "        folder = training_folder + '/scenarios/' + p + '/'\n",
    "        scenario_folders.append(folder)\n",
    "        input_folders.append(input_folder + p + '/')\n",
    "    \n",
    "print('input folder: ', input_folders)\n",
    "print('output folder: ', output_folder)\n",
    "print('scen folder : ', scenario_folders)\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dd746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_dict={'am':'AM','pm':'PM','ip':'IP','op':'OP'}\n",
    "\n",
    "# Logit Parameters\n",
    "logit_params ={'time': -0.00055,\n",
    "             'price': -1.0,\n",
    "             'transfers': -0.25,\n",
    "             'mode': 1.0,\n",
    "             'pt_mode': 0.5,\n",
    "             'pt_path': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e2476",
   "metadata": {},
   "source": [
    "# reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6803f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:04<00:00,  5.33it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 25.04it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n",
      "pm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:04<00:00,  5.86it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 24.18it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n",
      "ip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:04<00:00,  5.84it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 25.01it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n",
      "op\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:02<00:00,  8.94it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 36.55it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n"
     ]
    }
   ],
   "source": [
    "# run that locally and save resulting geojson in inputs (will be dockerize)\n",
    "if not on_lambda:\n",
    "    volumes = pd.read_csv(input_folder+'base/volumes/volumes.csv')\n",
    "\n",
    "    volumes.index.name = 'index'\n",
    "    volumes['origin'] = 'zone_' + volumes['origin'].astype(str)\n",
    "    volumes['destination'] = 'zone_' + volumes['destination'].astype(str)\n",
    "\n",
    "    for period, ref_folder, scen_folder in zip(periods,input_folders,scenario_folders):\n",
    "        print(period)\n",
    "\n",
    "        sm = stepmodel.read_zippedpickles(scen_folder + 'model/ref_los')\n",
    "\n",
    "        #volumes\n",
    "        v = volumes[volumes['time_period'] == period_dict[period]]\n",
    "        v = v[v['vehicle_class'].isin(['RPAX','BPAX'])]\n",
    "        v = v.groupby(['origin','destination','vehicle_class'])['volume'].sum().unstack().reset_index().fillna(0)\n",
    "        v.index.name='index'\n",
    "        sm.volumes = v\n",
    "\n",
    "        #links preparation\n",
    "        rename = lambda ls: ['rlink_'+ str(x).replace('rlink_','') for x in ls]\n",
    "        sm.links['road_link_list'] = sm.links['road_link_list'].apply(rename)\n",
    "        sm.links.index.name='index'\n",
    "\n",
    "\n",
    "        #logit prep\n",
    "        sm.preparation_logit(segments=['BPAX', 'RPAX'], **logit_params)\n",
    "\n",
    "        sm.segments = ['BPAX', 'RPAX']\n",
    "        sm.mode_utility.loc['rail','BPAX'] = -2\n",
    "        sm.mode_utility.loc['bus','RPAX'] = -2\n",
    "\n",
    "        #sm.analysis_pt_los(walk_on_road=True)\n",
    "        #sm.analysis_pt_route_type(hierarchy=[ 'car','rail', 'subway', 'tram', 'bus', 'walk'])\n",
    "\n",
    "        sm.los = sm.pt_los\n",
    "        sm.los = sm.los.reset_index()\n",
    "\n",
    "        sm.los['time'] = sm.los['gtime']\n",
    "        sm.los['price'] = 0\n",
    "\n",
    "        # Logit\n",
    "        sm.analysis_mode_utility(how='sum')\n",
    "\n",
    "        sm.step_logit(n_paths_max=10, workers=1, nchunks=10)\n",
    "\n",
    "        sm.step_assignment(\n",
    "                road=True, \n",
    "                boardings=True, \n",
    "                alightings=True, \n",
    "                transfers=True,\n",
    "                segmented=False,\n",
    "                boarding_links=False,\n",
    "                alighting_links=False)\n",
    "\n",
    "        #export\n",
    "        filename = input_folder+'{p}/loaded_links.geojson'.format(p=period)\n",
    "        sm.links.to_crs(4326).drop(columns=['road_link_list']).to_file(filename,driver='GeoJSON')\n",
    "\n",
    "        #sm.road_links.columns = [str(col) for col in sm.road_links.columns]\n",
    "        #filename = input_folder+'{p}/loaded_road_links.geojson'.format(p=period)\n",
    "        #sm.road_links.to_crs(4326).to_file(filename,driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e150cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12b1a667",
   "metadata": {},
   "source": [
    "# affectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5079b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = pd.read_csv(output_folder+'volumes.csv')\n",
    "\n",
    "volumes.index.name = 'index'\n",
    "volumes['origin'] = 'zone_' + volumes['origin'].astype(str)\n",
    "volumes['destination'] = 'zone_' + volumes['destination'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc2780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:04<00:00,  5.37it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 23.67it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n",
      "pm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:04<00:00,  5.72it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 18.19it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n",
      "ip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:04<00:00,  5.71it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 22.49it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n",
      "op\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "road_nodes: 100%|███████████████████████████████| 26/26 [00:03<00:00,  7.90it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 36.25it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to assign boardings on links pass boarding_links=True\n"
     ]
    }
   ],
   "source": [
    "for period, ref_folder, scen_folder in zip(periods,input_folders,scenario_folders):\n",
    "    print(period)\n",
    "\n",
    "    sm = stepmodel.read_zippedpickles(scen_folder + 'model/los')\n",
    "\n",
    "    #volumes\n",
    "    v = volumes[volumes['time_period'] == period_dict[period]]\n",
    "    v = v[v['vehicle_class'].isin(['RPAX','BPAX'])]\n",
    "    v = v.groupby(['origin','destination','vehicle_class'])['volume'].sum().unstack().reset_index().fillna(0)\n",
    "    v.index.name='index'\n",
    "    sm.volumes = v\n",
    "\n",
    "    #links preparation\n",
    "    rename = lambda ls: ['rlink_'+ str(x).replace('rlink_','') for x in ls]\n",
    "    sm.links['road_link_list'] = sm.links['road_link_list'].apply(rename)\n",
    "    sm.links.index.name='index'\n",
    "\n",
    "\n",
    "    #logit prep\n",
    "    sm.preparation_logit(segments=['BPAX', 'RPAX'], **logit_params)\n",
    "\n",
    "    sm.segments = ['BPAX', 'RPAX']\n",
    "    sm.mode_utility.loc['rail','BPAX'] = -2\n",
    "    sm.mode_utility.loc['bus','RPAX'] = -2\n",
    "\n",
    "    #sm.analysis_pt_los(walk_on_road=True)\n",
    "    #sm.analysis_pt_route_type(hierarchy=[ 'car','rail', 'subway', 'tram', 'bus', 'walk'])\n",
    "\n",
    "    sm.los = sm.pt_los\n",
    "    sm.los = sm.los.reset_index()\n",
    "\n",
    "    sm.los['time'] = sm.los['gtime']\n",
    "    sm.los['price'] = 0\n",
    "\n",
    "    # Logit\n",
    "    sm.analysis_mode_utility(how='sum')\n",
    "\n",
    "    sm.step_logit(n_paths_max=10, workers=1, nchunks=10)\n",
    "\n",
    "    sm.step_assignment(\n",
    "            road=True, \n",
    "            boardings=True, \n",
    "            alightings=True, \n",
    "            transfers=True,\n",
    "            segmented=False,\n",
    "            boarding_links=False,\n",
    "            alighting_links=False)\n",
    "    \n",
    "    #add reference values\n",
    "    \n",
    "    ref_links = gpd.read_file(input_folder+'{p}/loaded_links.geojson'.format(p=period))\n",
    "    ref_links = ref_links.set_index('index')\n",
    "    \n",
    "    sm.links['volume_ref'] = ref_links['volume']\n",
    "    sm.links['volume_diff'] = sm.links['volume'] - sm.links['volume_ref']\n",
    "    \n",
    "    sm.links['time_congestion_diff'] = sm.links['time_congestion'] - sm.links['time_ref']\n",
    "\n",
    "    #export\n",
    "    filename = output_folder+'loaded_links_{p}.geojson'.format(p=period)\n",
    "    sm.links.to_crs(4326).drop(columns=['road_link_list']).to_file(filename,driver='GeoJSON')\n",
    "\n",
    "    sm.road_links.columns = [str(col) for col in sm.road_links.columns]\n",
    "    filename = output_folder+'loaded_road_links_{p}.geojson'.format(p=period)\n",
    "    sm.road_links.to_crs(4326).to_file(filename,driver='GeoJSON')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf23af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56327c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
